ifndef::imagesdir[:imagesdir: images]
ifndef::sourcedir[:sourcedir: ../../../../lc-issuance-api/src/test/java/com/premonition/lc/issuance/domain]
[.text-justify]

== Implementing Domain Logic (20 pages)

[quote, Eric Evans]
To communicate effectively, the code must be based on the same language used to write the requirementsâ€”the same language that the developers speak with each other and with domain experts.

In the section on <<command-query-responsibility-segregation-cqrs>>, we described how DDD and CQRS complement each other and how the command side (write requests) is the home of business logic.In this chapter, we will implement the command side API for the LC application using https://spring.io/projects/spring-boot[Spring Boot]footnote:[https://spring.io/projects/spring-boot] and https://axoniq.io/product-overview/axon-framework[Axon Framework]footnote:[https://axoniq.io/product-overview/axon-framework].We will also look at how to implement structural and business validations using https://beanvalidation.org/[JSR-303 Bean Validations]footnote:[https://beanvalidation.org/]. and persistence options by contrasting between state-stored vs event-sourced aggregates.We will round off by looking at publishing state changes to the outside world in the form of domain events and exposing a HTTP API for commands.

=== Technical Requirements
* Java 1.8+ (We have used Java 14 to compile sample sources)
* Maven 3.x
* Spring Boot 2.4.*
* JUnit 5.7.x (Included with spring boot)
* Axon Framework 4.4.7 (DDD and CQRS Framework)
* Project Lombok (To reduce verbosity)
* Karate 1.0.1 (API Testing)
* Moneta 1.4.x (Money and currency reference implementation - JSR 354)

=== Command Query Responsibility Segregation (CQRS)
In this chapter, we will make use of the Command Query Responsibility Segregation (CQRS) architecture pattern to express the domain logic for our solution. The CQRS pattern strictly separates *write* (those that mutate state) and *read* (those that answer questions) operations.

==== Recap: What is CQRS
In traditional applications, a single data/persistence model is used to handle all kinds of operations. With CQRS, we create distinct models to handle updates and enquiries. This is depicted in the following diagram:

.Traditional vs. CQRS Architecture
image::cqrs/traditional-vs-cqrs-architecture.png[]

NOTE: We depict a single read model above for brevity. In reality though, more than one read model may need to be created, depending on the kinds of use cases that need to be supported.

For this to work predictably, the read model(s) need to be kept in sync with the write models (we will examine some of these techniques in detail later.

==== Why CQRS
The traditional, single-model approach works well for simple, CRUD-style applications, but starts to become unwieldy for more complex scenarios. We discuss some of these scenarios below:

* *Volume imbalance between read and writes*: In most systems, read operations often outnumber write operations by significant orders of magnitude. For example, consider the number of times a trader checks stock prices vs. the number of times they actually transact (buy or sell stock trades). It is also usually true that write operations are the ones that make businesses money. Having a single model for both reads and writes in a system with a majority of read operations can overwhelm a system to an extent where write performance can start getting affected.

* *Need for multiple read representations*: When working with relatively complex systems, it is not uncommon to require more than one representation of the same data. For example, when looking at personal health data, one may want to look at a daily, weekly, monthly view. While these views can be computed on the fly from the _raw_ data, each transformation (aggregation, summarization, etc.) adds to the cognitive load on the system. Several times, it is not possible to predict ahead of time, the nature of these requirements. By extension, it is not feasible to design a single canonical model that can provide answers to all these requirements. Creating domain models specifically designed to meet a focused set of requirements can be much easier.

* *Different security requirements*: Managing authorization and access requirements to data/APIs when working a single model can start to become cumbersome. For example, higher levels of security may be desirable for debit operations in comparison to balance enquiries. Having distinct models can considerably ease the complexity in designing fine-grained authorization controls.

* *More uniform distribution of complexity*: Having a single model to serve all use cases means that they can now be focused towards solving a single concern and thereby reduce complexity. It is worth noting that the essence of domain-driven design is mainly to work effectively with complex software systems and CQRS fits well with this line of thinking.

NOTE: Implementing CQRS does not require the use of any framework. However, in this book we will look at using Axon Framework because in our opinion it provides a set of conveniences while staying out of the way. There are other frameworks that work comparably, like Lagom Framework (https://www.lagomframework.com/) and Eventuate (https://eventuate.io/) that are worth exploring as well.

=== Bootstrapping the application

To get started, let's create a simple spring boot application using the following command:
[source,bash]
----
curl -G https://start.spring.io/starter.zip \ # <1>
       -d dependencies=web,data-jpa,lombok,validation,h2,actuator \ # <2>
       -d name=lc-issuance-api \
       -d artifactId=lc-issuance-api \
       -d groupId=com.example.api \
       -d packaging=jar \
       -d description='LC Issuance API' \
       -d package-name=com.example.api \
       -o lc-issuance-api.zip # <3>
----
<1> The spring initializr to create the application archive in zip form
<2> The list of dependencies separated by a comma
<3> The name of the archive containing the generated sources

NOTE: Alternatively, you can use use the spring initializr directly at https://start.spring.io or the spring boot CLI to generate the application.

This should create a file named `lc-issuance-api.zip` in the current directory. Unzip this file to a location of your choice and add a dependency on the Axon framework in the `dependencies` section of the `pom.xml` file:

[source,xml,linenum]
----
    <dependency>
        <groupId>org.axonframework</groupId>
        <artifactId>axon-spring-boot-starter</artifactId>
        <version>${axon-framework.version}</version> <!--1-->
    </dependency>
----
<1> You may need to change the version

Also, add the following dependency on the `axon-test` library to enable unit testing of aggregates:
[source,xml,linenum]
----
    <dependency>
        <groupId>org.axonframework</groupId>
        <artifactId>axon-test</artifactId>
        <scope>test</scope>
        <version>${axon-framework.version}</version>
    </dependency>
----

With the above set up, you should be able to run the application and start implementing the LC issuance functionality.

As a reminder, this is the output produced from our eventstorming session:

image::event-storming/05-read-models.png[]

The blue stickies in this diagram represent commands. Let's look at how to implement these commands using the Axon framework.

=== Command handling
From the eventstorming session, we have the following commands:

[.text-center]
[plantuml,potential-aggregates]
....
@startuml
skinparam handwritten true
skinparam CloudFontName "Gloria Hallelujah"
cloud Commands {
    cloud "Start LC Application"
    cloud "Submit LC Application"
    cloud "Validate Product"
    cloud "Validate Applicant"
    cloud "Approve LC Application"
    cloud "Decline LC Application"
    cloud "Issue LC"
}
@enduml
....
Commands are always directed to an aggregate for processing (handling). This means that we need to resolve each of these commands to be handled by an aggregate. While the sender of the command does not care which component within the system handles it, we need to decide which aggregate will handle each command. It is also important to note that any given command can only be handled by a single aggregate within the system. Let's look at how to group these commands and assign them to aggregates. To be able to do that, we need to identify the aggregates in the system first.

==== Aggregate design
Looking at the output of the eventstorming session, one potential grouping can be as follows:

.First cut attempt at aggregate design
image::aggregate-design/aggregate-design-01.png[]

At first glance, it appears that we have four potential entities to handle these commands:

.Potential aggregates at first glance
[.text-center]
[plantuml,potential-aggregates]
....
@startuml
skinparam handwritten true
skinparam CloudFontName "Gloria Hallelujah"
cloud "LC Application"
cloud Product
cloud Applicant
cloud LC
@enduml
....

At first glance, each of these entities may be classified as aggregates in our solution. Here, the `LC Application` feels like a reasonably good choice for aggregate, given that we are building a solution to manage LC applications. However, do the others make sense to be classified as such? The `Product` and `Applicant` look like potential entities, but we need to ask ourselves if we will need to operate on these outside of the purview of the `LC Application`. If the answer is a *yes*, then `Product` and `Applicant` _may_ be classified as aggregates. But both `Product` and `Applicant` do not seem to require being operated on without an enveloping `LC Application` within this bounded context. It feels that way because both product and applicant details are required to be provided as part of the LC application process. At least from what we know of the process thus far, this seems to be true. This means we are left with two potential aggregates -- `LC` and `LC Application`.

.Slightly more refined aggregate structure
[.text-center]
[plantuml,lc-application]
....
@startuml
skinparam CloudFontName "Gloria Hallelujah"
skinparam handwritten true
cloud "LC Application" as App {
  cloud Product
  cloud Applicant
}
cloud LC

@enduml
....

When we look at the output of our eventstorming session, the `LC Application` transitions to become an `LC` much later in the lifecycle. Let's work on the `LC Application` right now, and suspend further analysis on the need for the `LC` aggregate to a later time.

NOTE: For a more detailed explanation of the differences between aggregates, aggregate roots, entities and value objects, refer to Chapter 2.

Let's start writing our first command to see how this manifests itself in code.

==== Test-driving the system
While we have a reasonably good conceptual understanding of the system, we are still in the process of refining this understanding. Test-driving the system allows us to exercise our understanding by acting as the first client of the solution that we are producing.

NOTE: This is very well illustrated in the best-selling book -- _Growing Object-Oriented Software, Guided by Tests_ by authors Nat Price and Steve Freeman. This is worth looking at, to gain a deeper understanding of this practice.

So let's start with the first test. To the external world, an event-driven system typically works in a manner depicted below:

.An event-driven system
[.text-center]
image::event-driven-system.png[]

An optional set of events may have occurred in the past. A command is received by the system (initiated manually by a user or automatically by a part of the system), which acts as a stimulus. The system will react in one of two ways when it handles a command:

* Emit one or more events
* Throw an exception

The Axon framework allows us to express tests in this form. This is outlined below:

[source,java,linenum]
----
include::{sourcedir}/ch05/LCApplicationAggregateTests.java[lines=13..32]
}
----
<1> `FixtureConfiguration` is an Axon framework utility to aid testing of aggregate behaviour using a BDD style given-when-then syntax.
<2> `AggregateTestFixture` is a concrete implementation of `FixtureConfiguration` where you need to register your aggregate class -- `LCApplication` in our case as the candidate to handle commands directed to our solution.
<3> Since this is the start of the business process, there are no events that have occurred thus far. This is signified by the fact that we do not pass any arguments to the `given` method. In other examples we will discuss later, there will likely be events that have already occurred prior to receiving this command.
<4> This is where we instantiate a new instance of the command object. Command objects are usually similar to data transfer objects, carrying a set of information. This command will be routed to our aggregate for handling. We will take a look at how this works in detail shortly.
<5> Here we are declaring that we expect events matching an exact sequence.
<6> Here we are expecting an event of type `LCApplicationCreated` to be emitted as a result of successfully handling the command.
<7> We are finally saying that we do not expect any more events -- which means that we expect exactly one event to be emitted.

==== Command
The `CreateLCApplicationCommand` in the simplistic example above does not carry any state. Realistically, the command will likely look something like what is depicted below:

[source,java,linenum]
....
import lombok.Data;

@Data
public class CreateLCApplicationCommand {  // <1>

    private LCApplicationId id;            // <2>
    private ClientId clientId;
    private Party applicant;               // <3>
    private Party beneficiary;
    private AdvisingBank advisingBank;     // <3>
    private LocalDate issueDate;
    private MonetaryAmount amount;
    private String merchandiseDescription;

}

....
<1> The command class. When naming commands, we typically use an imperative style i.e. they usually begin with a verb denoting the action required. Note that this is a data transfer object. In other words, it is simply a bag of data attributes. Also note how it is devoid of any logic (at least at the moment).
<2> The identifier for the LC Application. We are assuming client generated identifiers in this case. The topic of using server-generated vs. client-generated identifiers is out of scope for the subject of this book. You may use either depending on what is advantageous in your context. Also note that we are using a strong type for the identifier `LCApplicationId` as opposed to a primitive such as a numeric or a string value. It is also common in some cases to use UUIDs as the identifier. However, we prefer using strong types to be able to differentiate between identifier types. Notice how we are using a type `ClientId` to represent the creator of the application.
<3> The `Party` and `AdvisingBank` types are complex types to represent those concepts in our solution. Care should be taken to consistently use names that are relevant in the problem (business) domain as opposed to using names that only make sense in the solution (technology) domain. Note the attempt to make use of the _ubiquitous language_ of the domain experts in both cases. This is a practice that we should always be conscious of when naming things in the system.

The astute reader will have noted that the `merchandiseDescription` is left as a primitive `String` type. This may feel contradictory to the commentary we present above. We will address this in the upcoming section on validations.

==== Event
A simplified representation of a real-world `LCApplicationCreatedEvent` is shown below:

[source,java,linenum]
....
import lombok.Data;

@Data
public class LCApplicationCreatedEvent {   // <1>

    private LCApplicationId id;
    private ClientId clientId;
    private Party applicant;
    private Party beneficiary;
    private AdvisingBank advisingBank;
    private LocalDate issueDate;
    private MonetaryAmount amount;
    private String merchandiseDescription;

}
....
<1> The event type. When naming events, we typically use names in the past tense to denote things that have already occurred and are to be accepted unconditionally as empirical facts that cannot be changed.

You will likely notice that the structure of the event is currently identical to that of the command. While this is true in this case, it may not always be that way. The amount of information that we choose to disclose in an event is context-dependent. It is important to consult with domain experts when publishing information as part of events. One may choose to withhold certain information in the event payload. For example, consider a `ChangePasswordCommand` which contains the newly changed password. It might be prudent to not include the changed password in the resulting `PasswordChangedEvent`.

We have looked at the command and the resulting event in the test above. Let's look at how this is implemented under the hood by looking at the aggregate implementation.

==== Aggregate
The aggregate is the place where commands are handled and events are emitted. The good thing about the test that we have written is that it is expressed in a manner that hides the implementation details. But let's look at the implementation to be able to appreciate how we can get our tests to pass and meet the business requirement.

[source,java,linenum]
----
include::{sourcedir}/ch05/LCApplication.java[lines=12..32]
    }
}
----
<1> The aggregate identifier for the `LCApplication` aggregate. All aggregates are required to declare an identifier and mark it so using the `@AggregateIdentifier` annotation provided by the framework.
<2> The method that is handling the command needs to be annotated with the `@CommandHandler` annotation. In this case, the command handler happens to be the constructor of the class given that this the first command that can be received by this aggregate. We will see examples of subsequent commands being handled by other methods later in the chapter.
<3> The `@CommandHandler` annotation marks a method as being a command handler. The exact command that this method can handle needs to be passed as a parameter to the method. Do note that there can only be one command handler in the *entire* system for any given command.
<4> Here, we are emitting the `LCApplicationCreatedEvent` using the `AggregateLifecycle` utility provided by the framework. In this very simple case, we are emitting an event unconditionally on receipt of the command. In a real-world scenario, it is conceivable that a set of validations will be performed before deciding to either emit one or more events or failing the command with an exception. We will look at more realistic examples later in the chapter.
<5> The need for the `@EventSourcingHandler` and its role are likely very unclear at this time. We will explain the need for this in detail in an upcoming section of this chapter.

This was a whirlwind introduction to a simple event-driven system. We still need to understand the role of the
`@EventSourcingHandler`. To understand that, we will need to appreciate how aggregate persistence works and the implications it has on our overall design.

[#_persisting_aggregates]
=== Persisting aggregates
When working with any system of even moderate complexity, we are required to make interactions durable. That is, interactions need to outlast system restarts, crashes, etc. So the need for persistence is a given. While we should always endeavour to abstract persistence concerns from the rest of the system, our persistence technology choices can have a significant impact on the way we architect our overall solution. We have a couple of choices in terms of how we choose to persist aggregate state that are worth mentioning:
1. State stored
2. Event sourced

Let's examine each of these techniques in more detail below:

==== State stored aggregates
Saving current values of entities is by far the most popular way to persist state -- thanks to the immense popularity of relational databases and object-relational mapping (ORM) tools like Hibernate. And there is good reason for this ubiquity. Until recently, a majority of enterprise systems used relational databases almost as a default to create business solutions, with ORMs arguably providing a very convenient mechanism to interact with relational databases and their object representations. For example, for our `LCApplication`, it is conceivable that we could use a relational database with a structure that would look something like below:

.Typical entity relationship model
[.text-center]
[plantuml,relational-structure]
....
@startuml
skinparam handwritten true
skinparam CloudFontName "Gloria Hallelujah"
skinparam linetype ortho
entity applicant {
    * id: number <<generated>>
    --
    * name
    * address
}
entity lc_application {
    * id: number <<generated>>
    --
    * amount: number
    * status: text
    merchandise_description
    * application_date
    * applicant_id: number <<FK>>
    * issuing_bank_id: number <<FK>>
    * advising_bank_id: number <<FK>>
}
entity document_clause {
  * id: number <<generated>>
  --
  description
  * lc_application_id: number <<FK>>
}
entity beneficiary {
  * id: number <<generated>>
  --
  name: text
  address: text
}
entity advising_bank {
  * id: number <<generated>>
  --
  * name: text
  * address: text
  * swift_id: number
}
entity issuing_bank {
  * id: number <<generated>>
  --
  * name: text
  * address: text
  * swift_id: number
}
applicant ||--o{ lc_application
lc_application ||--|{ document_clause
lc_application }o--|| beneficiary
lc_application }o--|| advising_bank
lc_application }o--|| issuing_bank
@enduml
....
Irrespective of whether we choose to use a relational database or a more modern NoSql store -- for instance, a document store, key-value store, column family store, etc., the style we use to persist information remains more or less the same -- which is to store the current values of the attributes of the said aggregate/entity. When the values of attributes change, we simply overwrite old values with newer ones i.e. we store the current state of aggregates and entities -- hence the name _state stored_. This technique has served us very well over the years, but there is at least one more mechanism that we can use to persist information. We will look at this in more detail below.

==== Event sourced aggregates
Developers have also been relying on logs for a variety of diagnostic purposes for a very long time. Similarly, relational databases have been employing commit logs to store information durably almost since their inception. However, developers' use of logs as a first class persistence solution for structured information in mainstream systems remains extremely rare.

NOTE: A log is an extremely simple, append-only ordered sequence of records

==== Which persistence mechanism should we choose?

=== Policy enforcements (validations)
When processing commands, we need to enforce policies or rules. Policies come in two broad categories:

* Structural rules -- those that enforce that the syntax of the dispatched command is valid.
* Domain rules -- those that enforce that business rules are adhered to.

It may also be prudent to perform these validations in different layers of the system.And it is also common for some or all of these policy enforcements to be repeated in more than one layer of the system.However, the important thing to note is that before a command is successfully handled, all these policy enforcements are uniformly applied.Let's look at some examples of these in the upcoming section.

==== Structural validations
Currently, to create an LC application, one is required to dispatch a `CreateLCApplicationCommand`. While the command dictates a structure, none of it is enforced at the moment. Let's correct that.

To be able to enable validations declaratively, we will make use of the JSR-303 bean validation libraries. We can add that easily using the `spring-boot-starter-validation` dependency to our `pom.xml` file as shown below:

[source,xml,linenum]
....
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-validation</artifactId>
    </dependency>

....

Now we can add validations to the command object using the JSR-303 annotations as depicted below:

[source,java,linenum]
....
import lombok.Data;
import javax.validation.*;
import javax.validation.constraints.*;

@Data
public class CreateLCApplicationCommand {

    @NotNull
    private LCApplicationId id;

    @NotNull
    private ClientId clientId;

    @NotNull
    @Valid
    private Party applicant;

    @NotNull
    @Valid
    private Party beneficiary;

    @NotNull
    @Valid
    private AdvisingBank advisingBank;

    @Future
    private LocalDate issueDate;

    @Positive
    private MonetaryAmount amount;

    @NotBlank
    private String merchandiseDescription;
}

....
Most structural validations can be accomplished using the built-in validator annotations. It is also possible to create custom validators for individual fields or to validate the entire object (for e.g. to validate inter-dependent attributes). For more details on how to do this, please refer to the bean validation specification at https://beanvalidation.org/2.0/ and the reference implementation at http://hibernate.org/validator/.

==== Business rule enforcements
Structural validations can be accomplished using information that is already available in the command.However, there is another class of validations that requires information that is not present in the incoming command itself.This kind of information can be present in one of two places -- within the aggregate that we are operating on or outside of the aggregate itself, but made available within the bounded context.

Let's look at an example of a validation that requires state present within the aggregate. Consider the example of submitting an LC.While we can make several edits to the LC when it is in draft state, no changes can be made after it is submitted.This means that we can only submit an LC once.This act of submitting the LC is achieved by issuing the `SubmitLCApplicationCommand` as shown in the artifact from the eventstorming session:

image::aggregate-state-validation.png[]

Let's begin with a test to express our intent:
[source,java,linenum]
....
include::{sourcedir}/ch05/LCApplicationAggregateTests.java[lines=48..58,indent=0]
....
<1> Given that the `LCApplicationCreatedEvent` has already occurred -- in other words, the LC application is already created.
<2> When we try to submit the application by issuing the `SubmitLCApplicationCommand`.
<3> We expect the `LCApplicationSubmittedEvent` to be emitted.

The corresponding implementation will look something like below:

[source,java,linenum]
....
include::{sourcedir}/ch05/LCApplication.java[lines=48..49,indent=0]
include::{sourcedir}/ch05/LCApplication.java[lines=53..54,indent=0]
....

The implementation above will allow us to submit an LC application more than once. However, we want to restrict users to be able to submit only once. To be able to do that, we need to remember that the LC application has already been submitted. We can do that in the `@EventSourcingHandler` of the corresponding events as shown below:

[source,java,linenum]
....
@EventSourcingHandler
include::{sourcedir}/ch05/LCApplication.java[lines=32..35,indent=0]

include::{sourcedir}/ch05/LCApplication.java[lines=56..59,indent=0]
....

While we have remembered that the application has changed to be in `SUBMITTED` state, we are still not preventing more than one submit attempt. We can fix that by writing a test as shown below:

[source,java,linenum]
....
include::{sourcedir}/ch05/LCApplicationAggregateTests.java[lines=34..46,indent=0]
....
<1> The `LCApplicationCreatedEvent` and `LCApplicationSubmittedEvent` have already happened.
<2> We now dispatch a `SubmitLCApplicationCommand` to the system.
<3> We expect an `AlreadySubmittedException` to be thrown.
<4> We also expect no events to be emitted.

The implementation of the command handler to make this work is shown below:

[source,java,linenum]
....
include::{sourcedir}/ch05/LCApplication.java[lines=48..55,indent=0]
....
<1> Note how we are using the state attribute from the `LCApplication` aggregate to perform the validation. If the application is not in `DRAFT` state, we fail with the `AlreadySubmittedException` domain exception.

Let's also look at an example where information needed to perform the validation is not part of either the command or the aggregate. Let's consider the scenario where country regulations prohibit transacting with a set of so called _sanctioned_ countries. Changes to this list of countries may be affected by external factors. It does not make sense to pass this list of sanctioned countries as part of the command payload. Neither does it make sense to maintain it as part of the aggregate state. In such a case, we may want to consider making use of a command handler that is outside the confines of the aggregate class. Thus far, we have only seen examples of `@CommandHandler` methods within the aggregate. But the `@CommandHandler` annotation can appear on any other class external to the aggregate. However, in such a case, we need to load the aggregate ourselves. The Axon framework provides a `org.axonframework.modelling.command.Repository` interface to allow us to do that as shown below:

[source,java,linenum]
....
import org.axonframework.modelling.command.Repository;

class MyCustomCommandHandler {

    private final Repository<LCApplication> repository; // <1>

    MyCustomCommandHandler(Repository<LCApplication> repository) {
        this.repository = repository;  // <1>
    }

    @CommandHandler
    public void handle(SomeCommand command) {
        Aggregate<LCApplication> application = repository.load(command.getAggregateId());  // <2>
        // Command handling code
    }

    @CommandHandler
    public void handle(AnotherCommand command) {
        Aggregate<LCApplication> application = repository.load(command.getAggregateId());
        // Command handling code
    }
}
....
<1> We are injecting the Axon `Repository` to allow us to load aggregates
<2> We are using the `Repository` to load aggregates and work with them.

Coming back to the sanctioned countries example, let's look at the test implementation:
[source,java,linenum]
....
include::{sourcedir}/ch05/CreateLCApplicationCommandHandlerTests.java[lines=21..34,indent=0]
}
....
<1> We are creating a new aggregate fixture like usual
<2> We are using the fixture to obtain an instance of the Axon `Repository`
<3> We instantiate the custom command handler passing in the `Repository` instance. Also note how we inject the collection of sanctioned countries into the handler using simple dependency injection. In real life, this set of sanctioned countries will likely be obtained from external configuration.
<4> We finally need to register the command handler with the fixture, so that it can route commands to this handler.

The tests for this look fairly straightforward:

[source,java,linenum]
....
include::{sourcedir}/ch05/CreateLCApplicationCommandHandlerTests.java[lines=32..45,indent=0]
....
The implementation of the command handler is shown below:

[source,java,linenum]
....
include::{sourcedir}/ch05/CreateLCApplicationCommandHandler.java[lines=7..,indent=0]
....

Finally, the aggregate implementation along with the validation is shown below:
[source,java,linenum]
....
class LCApplication {
// ...
include::{sourcedir}/ch05/LCApplication.java[lines=37..42]

// ...
}
....

=== Publishing events

=== Exposing a REST-based API for commands
